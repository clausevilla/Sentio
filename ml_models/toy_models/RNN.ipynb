{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b25dbb5a-ab3d-41bf-a9b0-692701365bb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "print(os.path.exists(r'../../data/data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1fcc85ea-aeb2-4215-bea9-70b9a156693c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Anxiety', 'Normal', 'Depression', 'Suicidal', 'Stress', 'Bipolar',\n",
       "       'Personality disorder'], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'../../data/data.csv')\n",
    "\n",
    "df['status'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d9845aa6-1438-4279-8631-c2254705dbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53043 entries, 0 to 53042\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  53043 non-null  int64 \n",
      " 1   statement   52681 non-null  object\n",
      " 2   status      53043 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()\n",
    "df.isna().sum()\n",
    "\n",
    "label_map = {\n",
    "    \"Normal\": 0,\n",
    "    \"Depression\": 1,\n",
    "    \"Suicidal\": 2,\n",
    "    \"Anxiety\": 3,\n",
    "    \"Stress\": 4,\n",
    "    \"Bipolar\": 5,\n",
    "    \"Personality disorder\": 6\n",
    "}\n",
    "\n",
    "df['status'] = df['status'].map(label_map)\n",
    "df['status'] = df['status'].astype(int)\n",
    "#Converts the statement column to a string\n",
    "df['statement'] = df['statement'].astype(str)\n",
    "#Makes the text all lowercase \n",
    "df['statement'] = df['statement'].astype(str).str.lower()\n",
    "#Drops the rows where the text is missing\n",
    "df = df.dropna(subset=['status'])\n",
    "\n",
    "#Removes punctuation\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df['statement'] = df['statement'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e78d4bbf-da6d-4b25-ad74-cb4a4730fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = df.sample(frac=0.75, random_state=42)\n",
    "test_df  = df.drop(train_df.index)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((\n",
    "    train_df['statement'].values,\n",
    "    train_df['status'].values\n",
    "))\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((\n",
    "    test_df['statement'].values,\n",
    "    test_df['status'].values\n",
    "))\n",
    "\n",
    "train_ds = train_ds.shuffle(10000).batch(32)\n",
    "test_ds = test_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0fd4466f-dc52-41ad-85bf-71784a8a9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: survey on situational stress and music 18 and up i am a research student doing research on situational stress please help me and complete my survey for this project thank you\n",
      "httpsformsglejdguzqmlxrncufxd7httpsformsglejdguzqmlxrncufxd7\n",
      "Encoded: [1673   27 4899  287    4  667  657    4   45    2   15    7 1180  916\n",
      "  157 1180   27 4899  287  265   83   11    4  873    6 1673   19   21\n",
      " 1682  438   29    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "Decoded: survey on situational stress and music 18 and up i am a research student doing research on situational stress please help me and complete my survey for this project thank you [UNK]                                                                                                                                                                        \n"
     ]
    }
   ],
   "source": [
    "# Create encoder (vectorizer)\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=10000,\n",
    "    output_sequence_length=200\n",
    ")\n",
    "\n",
    "# Adapt using *unbatched* text data\n",
    "encoder.adapt(\n",
    "    train_ds.unbatch().map(lambda text, label: text)\n",
    ")\n",
    "\n",
    "# Get vocabulary\n",
    "vocabulary = np.array(encoder.get_vocabulary())\n",
    "\n",
    "# Take a single example from dataset\n",
    "example_text, example_label = next(iter(train_ds.unbatch()))\n",
    "\n",
    "# Encode\n",
    "encoded = encoder(example_text)\n",
    "encoded_numpy = encoded.numpy()\n",
    "\n",
    "# Decode back to words\n",
    "decoded = ' '.join(vocabulary[encoded_numpy])\n",
    "\n",
    "print('Original:', example_text.numpy().decode())\n",
    "print('Encoded:', encoded_numpy)\n",
    "print('Decoded:', decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f411637e-21db-4740-9d8f-c98fcb0d0ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(1,), dtype=tf.string),\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(7)  # 7 classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "612dcedf-af47-4334-8d5f-435480b584c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9e36e1a7-6ee4-44f8-bef3-93199a0ab886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1244/1244 [==============================] - 762s 598ms/step - loss: 1.3222 - accuracy: 0.5413 - val_loss: 1.0038 - val_accuracy: 0.6052\n",
      "Epoch 2/10\n",
      "1244/1244 [==============================] - 847s 681ms/step - loss: 0.9285 - accuracy: 0.6552 - val_loss: 0.8576 - val_accuracy: 0.6713\n",
      "Epoch 3/10\n",
      "1244/1244 [==============================] - 741s 596ms/step - loss: 0.6340 - accuracy: 0.7377 - val_loss: 0.7195 - val_accuracy: 0.7162\n",
      "Epoch 4/10\n",
      "1244/1244 [==============================] - 33646s 27s/step - loss: 0.4865 - accuracy: 0.7819 - val_loss: 0.6876 - val_accuracy: 0.7409\n",
      "Epoch 5/10\n",
      "1244/1244 [==============================] - 731s 587ms/step - loss: 0.3896 - accuracy: 0.8156 - val_loss: 0.7121 - val_accuracy: 0.7480\n",
      "Epoch 6/10\n",
      "1244/1244 [==============================] - 3865s 3s/step - loss: 0.3354 - accuracy: 0.8339 - val_loss: 0.6944 - val_accuracy: 0.7577\n",
      "Epoch 7/10\n",
      "1244/1244 [==============================] - 1017s 818ms/step - loss: 0.2846 - accuracy: 0.8547 - val_loss: 0.7093 - val_accuracy: 0.7591\n",
      "Epoch 8/10\n",
      "1244/1244 [==============================] - 984s 791ms/step - loss: 0.2484 - accuracy: 0.8703 - val_loss: 0.8487 - val_accuracy: 0.7416\n",
      "Epoch 9/10\n",
      "1244/1244 [==============================] - 856s 688ms/step - loss: 0.2202 - accuracy: 0.8833 - val_loss: 0.7972 - val_accuracy: 0.7522\n",
      "Epoch 10/10\n",
      "1244/1244 [==============================] - 868s 698ms/step - loss: 0.1961 - accuracy: 0.8946 - val_loss: 0.8587 - val_accuracy: 0.7555\n"
     ]
    }
   ],
   "source": [
    "labels = train_df['status'].values\n",
    "#Automatically creates class weights based on how common the class is in the dataset\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced', classes=np.unique(labels), y=labels\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=test_ds,\n",
    "    class_weight=class_weights_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b8198311-cf6d-422c-a685-7c257b4afb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415/415 [==============================] - 78s 187ms/step - loss: 0.8587 - accuracy: 0.7555\n",
      "Test accuracy: 0.7555\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0274621b-b61a-4f6e-a7df-50bb2c5919d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 12s 12s/step\n",
      "[4 1]\n",
      "Text: I feel very stressed and anxious these days.\n",
      "Predicted label: Stress\n",
      "Text: I am happy and I feel normal\n",
      "Predicted label: Depression\n"
     ]
    }
   ],
   "source": [
    "new_texts = [\n",
    "    \"I feel very stressed and anxious these days.\",\n",
    "    \"I am happy and I feel normal\"\n",
    "]\n",
    "\n",
    "predictions = model.predict(new_texts)\n",
    "\n",
    "predicted_classes = tf.argmax(predictions, axis=1).numpy()\n",
    "\n",
    "print(predicted_classes)\n",
    "\n",
    "inv_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "for i, text in enumerate(new_texts):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted label: {inv_label_map[predicted_classes[i]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "45e580cd-daf8-42d5-9cb2-423f7d8f8a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 226ms/step\n",
      "Normal: 0.65\n",
      "Depression: 0.22\n",
      "Suicidal: 0.12\n",
      "Anxiety: 0.01\n",
      "Stress: 0.00\n",
      "Bipolar: 0.00\n",
      "Personality disorder: 0.00\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict([\"Everything is on fire around me and I don't know what to do\"])\n",
    "probs = tf.nn.softmax(preds, axis=1).numpy()\n",
    "for i, prob in enumerate(probs[0]):\n",
    "    print(f\"{inv_label_map[i]}: {prob:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706cdc3-9aad-487b-a03f-30d02096a7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cnnlab]",
   "language": "python",
   "name": "conda-env-.conda-cnnlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
