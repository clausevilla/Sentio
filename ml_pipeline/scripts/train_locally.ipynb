{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5Xz4Q3MNX_e"
   },
   "source": [
    "# Sentio Model Training\n",
    "#### (for testing outside application)\n",
    "\n",
    "Training notebook for mental health text classification models.\n",
    "\n",
    "**Available models:**\n",
    "- `logistic_regression` - Fast baseline, good for quick iteration\n",
    "- `random_forest` - Ensemble baseline\n",
    "- `lstm` - Bidirectional LSTM neural network\n",
    "- `transformer` - Custom transformer encoder (no pretrained weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths based on if running locally or in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/mbx/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mbx/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/mbx/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/mbx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/mbx/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment: Local\n",
      "Data dir: /home/mbx/Documents/projects/gitlab/sentio/data\n",
      "Output dir: /home/mbx/Documents/projects/gitlab/sentio/ml_pipeline/sentio_results/increment\n"
     ]
    }
   ],
   "source": [
    "# Author: Marcus Berggren\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # If you are using Google colab, upload both 'sentio/data/' and 'sentio/ml_pipeline' folders to Colab Notebooks folder on Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    PROJECT_ROOT = Path('/content/drive/MyDrive/Colab Notebooks')\n",
    "else:\n",
    "    PROJECT_ROOT = Path.cwd().parent.parent\n",
    "\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "from ml_pipeline.preprocessing.preprocessor import DataPreprocessingPipeline\n",
    "preprocessor = DataPreprocessingPipeline()\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'ml_pipeline' / 'sentio_results' / 'increment'\n",
    "\n",
    "print(f\"Environment: {'Colab' if IN_COLAB else 'Local'}\")\n",
    "print(f\"Data dir: {DATA_DIR}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QafbfcRwNguO"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    force=True # Should enforce logs to show\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjGsQHQUNoUn"
   },
   "source": [
    "## Configuration\n",
    "\n",
    "**Change `MODEL_TYPE` to train different models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyJRoL86NmZ1",
    "outputId": "cf13a694-737d-4f95-8c52-34b7560276fd"
   },
   "outputs": [],
   "source": [
    "# MODEL SELECTION\n",
    "# Options: 'logistic_regression', 'random_forest', 'lstm', 'transformer'\n",
    "MODEL_TYPE = 'random_forest'\n",
    "\n",
    "# TRAINING CONFIG\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Model-specific configs\n",
    "MODEL_CONFIGS = {\n",
    "    'logistic_regression': {\n",
    "        'max_iter': 1000,\n",
    "        'C': 1.0,\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': None,\n",
    "        'tfidf': {\n",
    "            'max_features': 10000,\n",
    "        },\n",
    "    },\n",
    "    'lstm': {\n",
    "        'embed_dim': 128,\n",
    "        'hidden_dim': 128,\n",
    "        'num_layers': 2,\n",
    "        'dropout': 0.2,\n",
    "        'epochs': 7,\n",
    "        'patience':3,\n",
    "        'batch_size': 64,\n",
    "        'learning_rate': 1e-3,\n",
    "        'max_seq_len': 256,\n",
    "        'vocab_size': 30000,\n",
    "    },\n",
    "    'transformer': {\n",
    "    'd_model': 256,\n",
    "    'nhead': 8,\n",
    "    'num_layers': 2,\n",
    "    'dim_feedforward': 256,\n",
    "    'dropout': 0.1,\n",
    "    'epochs': 15,\n",
    "    'patience': 3,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 1e-5,\n",
    "    'max_seq_len': 256,\n",
    "    'vocab_size': 30000,\n",
    "}\n",
    "}\n",
    "\n",
    "print(f'Model: {MODEL_TYPE}')\n",
    "print(f'Output: {OUTPUT_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JwlfFyjNq42"
   },
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsvwQMdT4DYz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Make sure you have the following csv files in 'sentio/data/' folder. In Django application data is taken from db.\n",
    "\n",
    "df_train = pd.read_csv(f'{DATA_DIR}/sentio-data-train.csv')\n",
    "X_train = df_train['text_preprocessed']\n",
    "y_train = df_train['label']\n",
    "\n",
    "df_test = pd.read_csv(f'{DATA_DIR}/sentio-data-test.csv')\n",
    "X_test_fixed = df_test['text_preprocessed']\n",
    "y_test_fixed = df_test['label']\n",
    "\n",
    "df_incremental = pd.read_csv(f'{DATA_DIR}/sentio-data-increment.csv')\n",
    "X_train_incremental = df_incremental['text_preprocessed']\n",
    "y_train_incremental = df_incremental['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hHTw0t-N1Nc",
    "outputId": "353979dc-292e-4964-bf51-d5e3c84e7401"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f'Train: {len(X_train):,} samples')\n",
    "print('Train label distribution:')\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f'  {label}: {count:,} ({count/len(y_train)*100:.1f}%)')\n",
    "\n",
    "print()\n",
    "print(f'Test: {len(X_test_fixed):,} samples')\n",
    "print('Test label distribution:')\n",
    "unique, counts = np.unique(y_test_fixed, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f'  {label}: {count:,} ({count/len(y_train)*100:.1f}%)')\n",
    "\n",
    "print()\n",
    "print(f'Incremental: {len(X_train_incremental):,} samples')\n",
    "print('Incremental label distribution:')\n",
    "unique, counts = np.unique(y_train_incremental, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f'  {label}: {count:,} ({count/len(y_train)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqmAj6RqN2kE"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nLQ3MQgsN377",
    "outputId": "6f8ca036-e882-41b0-a213-e452be29adac"
   },
   "outputs": [],
   "source": [
    "from ml_pipeline.training.trainer import ModelTrainer\n",
    "from ml_pipeline.storage.handler import StorageHandler\n",
    "from datetime import datetime\n",
    "\n",
    "storage = StorageHandler(OUTPUT_DIR)\n",
    "trainer = ModelTrainer(storage)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "job_id = f'{MODEL_TYPE}_{timestamp}'\n",
    "\n",
    "print(f'Job ID: {job_id}')\n",
    "print(f'Device: {trainer.device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KA1VGp8uN5bp",
    "outputId": "b6d11267-8475-4546-fbcb-fd8aad763f3d"
   },
   "outputs": [],
   "source": [
    "config = MODEL_CONFIGS.get(MODEL_TYPE, {})\n",
    "print(f'Config for {MODEL_TYPE}:')\n",
    "for key, value in config.items():\n",
    "    print(f'  {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zbAA9jj0N6b1",
    "outputId": "fb033efd-ff0e-433f-a2c6-1adb9c914a64"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f'Training {MODEL_TYPE}...')\n",
    "\n",
    "result = trainer.train(\n",
    "    model_name=MODEL_TYPE,\n",
    "    data=(X_train, y_train, X_test_fixed, y_test_fixed),\n",
    "    config=config,\n",
    "    job_id=job_id,\n",
    ")\n",
    "\n",
    "print('Training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeYM5QCGN8Nt"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wRJ9tbhVN7eP",
    "outputId": "10c82787-9ac5-47fd-913c-765c0ddb0adf"
   },
   "outputs": [],
   "source": [
    "print(f\"Status: {result['status']}\")\n",
    "print(f\"Model: {result['model_type']}\")\n",
    "print(f\"Path: {result['model_path']}\")\n",
    "print(\"Metrics:\")\n",
    "print(f\"  Accuracy:  {result['metrics']['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {result['metrics']['precision']:.4f}\")\n",
    "print(f\"  Recall:    {result['metrics']['recall']:.4f}\")\n",
    "print(f\"  F1 Score:  {result['metrics']['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "id": "ciXXzUV7N-n5",
    "outputId": "57ff2ee5-2d16-4d6b-ae44-1a3927dc511e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "cm = np.array(result['metrics']['confusion_matrix'])\n",
    "labels = result['metrics']['confusion_matrix_labels']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.title(f'Confusion Matrix - {MODEL_TYPE}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "\n",
    "cm_path = os.path.join(OUTPUT_DIR, f'{job_id}_confusion_matrix.png')\n",
    "plt.savefig(cm_path, dpi=150)\n",
    "plt.show()\n",
    "print(f'Saved: {cm_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yj4NTzjjN_8q",
    "outputId": "69360021-3b65-4844-de8e-3a4c184281d3"
   },
   "outputs": [],
   "source": [
    "print('Per-class metrics:')\n",
    "report = result['metrics']['classification_report']\n",
    "for label in labels:\n",
    "    if label in report:\n",
    "        m = report[label]\n",
    "        print(f\"{label:20} P: {m['precision']:.3f}  R: {m['recall']:.3f}  F1: {m['f1-score']:.3f}  Support: {m['support']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZx3U_dUOBFi",
    "outputId": "d60f581c-be2e-4f32-8c40-af233ab07a21"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "results_path = os.path.join(OUTPUT_DIR, f'{job_id}_results.json')\n",
    "\n",
    "save_results = {\n",
    "    'job_id': job_id,\n",
    "    'model_type': MODEL_TYPE,\n",
    "    'model_path': result['model_path'],\n",
    "    'config': config,\n",
    "    'data': {\n",
    "        'train_samples': len(X_train),\n",
    "        'test_samples': len(X_test_fixed),\n",
    "        'classes': list(set(y_train)),\n",
    "    },\n",
    "    'metrics': result['metrics'],\n",
    "    'timestamp': timestamp,\n",
    "}\n",
    "\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(save_results, f, indent=2)\n",
    "\n",
    "print(f'Saved: {results_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google colab does not have swifter installed\n",
    "if IN_COLAB:\n",
    "    !pip install swifter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3St2e4YOCSd"
   },
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JoHWQqkaODue",
    "outputId": "e70ca5ae-ef7c-4972-9161-17c550a7f28d"
   },
   "outputs": [],
   "source": [
    "from ml_pipeline.inference.predictor import Predictor\n",
    "\n",
    "test_texts = [\n",
    "    \"I feel so stressed and anxious about everything lately.\",\n",
    "    \"Life is great, I'm feeling happy and content.\",\n",
    "    \"I don't want to live anymore, everything is hopeless.\",\n",
    "    \"I can't stop crying and I feel so empty inside.\",\n",
    "    \"I am happy and stressed\"\n",
    "]\n",
    "\n",
    "# Load predictor\n",
    "predictor = Predictor(storage)\n",
    "predictor.load(result['model_path'])\n",
    "\n",
    "print('Sample predictions:')\n",
    "print('=' * 70)\n",
    "\n",
    "for text in test_texts:\n",
    "    # Preprocess text first (same as training)\n",
    "    processed = preprocessor._preprocess_single_text(text)\n",
    "\n",
    "    # Get prediction\n",
    "    pred = predictor.predict(processed)\n",
    "\n",
    "    print(f'\\nText: \"{text}\"')\n",
    "    print('-' * 70)\n",
    "\n",
    "    # Sort probabilities descending\n",
    "    sorted_probs = sorted(pred['probabilities'].items(), key=lambda x: -x[1])\n",
    "\n",
    "    for i, (label, prob) in enumerate(sorted_probs):\n",
    "        if i == 0:\n",
    "            print(f'  >>> {label:20} {prob*100:5.1f}% <<<')\n",
    "        else:\n",
    "            print(f'      {label:20} {prob*100:5.1f}%')\n",
    "\n",
    "print('\\n' + '=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpzYglL7OFew"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZo9dp8TOGbP",
    "outputId": "7209dac9-2b12-4945-8a80-6f1875becf3f"
   },
   "outputs": [],
   "source": [
    "base_accuracy = result[\"metrics\"][\"accuracy\"]\n",
    "\n",
    "print('=' * 60)\n",
    "print('TRAINING SUMMARY')\n",
    "print('=' * 60)\n",
    "print(f'Model:      {MODEL_TYPE}')\n",
    "print(f'Job ID:     {job_id}')\n",
    "print(f'Accuracy:   {base_accuracy:.4f}')\n",
    "print(f'F1 Score:   {result[\"metrics\"][\"f1_score\"]:.4f}')\n",
    "print(f'Model Path: {result[\"model_path\"]}')\n",
    "print('=' * 60)\n",
    "print(f'All outputs saved to: {OUTPUT_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuE3lLrYDeOH"
   },
   "source": [
    "\n",
    "## Incremental training (fine-tune existing model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "NOuyQHp_Db7A",
    "outputId": "26a0e614-8906-4cbf-dbf9-e234a14a6561"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "TRAINING_MODE = 'incremental'\n",
    "\n",
    "# Option 1: Use model from previous full training in this session\n",
    "# Option 2: Specify a path to any existing model\n",
    "USE_PREVIOUS_RESULT = True  # Set to False to use CUSTOM_MODEL_PATH\n",
    "\n",
    "CUSTOM_MODEL_PATH = str(OUTPUT_DIR / 'transformer_transformer_20251130_003457.pt')  # Your best model\n",
    "\n",
    "if USE_PREVIOUS_RESULT and result:\n",
    "    BASE_MODEL_PATH = result['model_path']\n",
    "    base_accuracy = result['metrics']['accuracy']\n",
    "    print(f\"Using model from this session: {BASE_MODEL_PATH}\")\n",
    "else:\n",
    "    BASE_MODEL_PATH = CUSTOM_MODEL_PATH\n",
    "    # Load base model metrics for comparison\n",
    "    checkpoint = storage.load_neural_model(BASE_MODEL_PATH)\n",
    "    print(f\"Using custom model: {BASE_MODEL_PATH}\")\n",
    "    print(\"Note: Run evaluation on base model first to get base_accuracy for comparison\")\n",
    "    base_accuracy = None  # Will need to evaluate separately\n",
    "\n",
    "print(f\"Base model: {BASE_MODEL_PATH}\")\n",
    "\n",
    "# Config for incremental\n",
    "incremental_config = {\n",
    "    'training_mode': 'incremental',\n",
    "    'base_model_path': BASE_MODEL_PATH,\n",
    "    'learning_rate': 1e-5,\n",
    "    'epochs': 5,\n",
    "    'patience': 3,\n",
    "    'batch_size': 32,\n",
    "    'max_seq_len': 256,\n",
    "    'expand_vocab': True,\n",
    "}\n",
    "\n",
    "print(f'Training {MODEL_TYPE}...')\n",
    "\n",
    "# Train incrementally, important to use fixed test data\n",
    "result = trainer.train(\n",
    "    model_name=MODEL_TYPE, # Set in the config\n",
    "    data=(X_train_incremental, y_train_incremental, X_test_fixed, y_test_fixed),\n",
    "    config=incremental_config,\n",
    "    job_id=f'transformer_incremental_{timestamp}',\n",
    ")\n",
    "\n",
    "print('Training complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShVnhyWiAZmj"
   },
   "source": [
    "### Run same tests again but after incremental train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mgPuIh3DAYyr",
    "outputId": "acb0a32d-95f2-4b44-e1fc-4a945b13e773"
   },
   "outputs": [],
   "source": [
    "test_texts = [\n",
    "    \"I feel so stressed and anxious about everything lately.\",\n",
    "    \"Life is great, I'm feeling happy and content.\",\n",
    "    \"I don't want to live anymore, everything is hopeless.\",\n",
    "    \"I can't stop crying and I feel so empty inside.\",\n",
    "    \"I am happy and stressed\"\n",
    "]\n",
    "\n",
    "# Load predictor\n",
    "predictor = Predictor(storage)\n",
    "predictor.load(result['model_path'])\n",
    "\n",
    "print('Sample predictions:')\n",
    "print('=' * 70)\n",
    "\n",
    "for text in test_texts:\n",
    "    # Preprocess text first (same as training)\n",
    "    processed = preprocessor._preprocess_single_text(text)\n",
    "\n",
    "    # Get prediction\n",
    "    pred = predictor.predict(processed)\n",
    "\n",
    "    print(f'\\nText: \"{text}\"')\n",
    "    print('-' * 70)\n",
    "\n",
    "    # Sort probabilities descending\n",
    "    sorted_probs = sorted(pred['probabilities'].items(), key=lambda x: -x[1])\n",
    "\n",
    "    for i, (label, prob) in enumerate(sorted_probs):\n",
    "        if i == 0:\n",
    "            print(f'  >>> {label:20} {prob*100:5.1f}% <<<')\n",
    "        else:\n",
    "            print(f'      {label:20} {prob*100:5.1f}%')\n",
    "\n",
    "print('\\n' + '=' * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kdj7NkpEbYJo",
    "outputId": "20fb4ced-45c6-471c-ded1-d7f74301446a"
   },
   "outputs": [],
   "source": [
    "print(f\"Incremental model accuracy: {result['metrics']['accuracy']:.4f}\")\n",
    "print(f\"Incremental model F1: {result['metrics']['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAcAiAFubgIF",
    "outputId": "21bf6083-f048-41d5-be7d-56a0edc6b1e9"
   },
   "outputs": [],
   "source": [
    "new_accuracy = result['metrics']['accuracy']\n",
    "\n",
    "if base_accuracy is not None:\n",
    "    print(f\"Base model:        {base_accuracy:.4f}\")\n",
    "    print(f\"Incremental model: {new_accuracy:.4f}\")\n",
    "    print(f\"Change:            {new_accuracy - base_accuracy:+.4f}\")\n",
    "\n",
    "    if new_accuracy > base_accuracy:\n",
    "        print(\"Model improved!\")\n",
    "    else:\n",
    "        print(f\"Model did not improve with adding {len(X_train_incremental)} rows of data\")\n",
    "else:\n",
    "    print(f\"Incremental model: {new_accuracy:.4f}\")\n",
    "    print(\"(Base accuracy not available - evaluate base model separately to compare)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_tcV4MdUWZV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
